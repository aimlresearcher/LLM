# 📘 Course Overview: Generative AI and Data Preparation for LLMs

Welcome to this short course on **Generative AI** and **Data Preparation for Large Language Models (LLMs)**. This is the **first course** in the **Generative AI Engineering Essentials with LLMs Professional Certificate** series.

This course is your **first step** toward understanding how to use **generative AI architectures** and **LLMs** like **Generative Pre-trained Transformers (GPT)** for **Natural Language Processing (NLP)**.

---

## 🧠 What You’ll Learn

In this course, you will:

- 📌 Understand the significance of **Generative AI** across different domains
- 🔍 Differentiate between **generative AI models** and architectures
- 🤖 Apply **LLMs** to NLP tasks
- 🧰 Explore key tools and libraries like **PyTorch** and **Hugging Face**
- 💬 Build a simple **chatbot** using the Transformers library
- 🧱 Learn and implement **tokenization techniques**
- 📦 Understand and use **data loaders** for training LLMs

---

## 🎯 Learning Outcomes

By the end of this course, you will be able to:

- ✅ Explain the role of generative AI in real-world use cases
- 🧠 Compare various generative AI architectures (e.g., **Transformers**, **GANs**, **VAEs**, **RNNs**, **Diffusion Models**)
- 📚 Describe the features of **LLMs** and how they apply to NLP tasks
- 🛠 Use **Hugging Face libraries** within a **Jupyter notebook**
- ✂️ Implement different **tokenization methods** (word, character, subword)
- 🔄 Create an **NLP data loader** using **PyTorch**
- 🔍 Understand the use of the `collate` function to process text batches

---

## 👨‍💻 Who Should Take This Course?

This course is ideal for:

- AI Engineers
- Machine Learning Engineers
- Data Scientists
- Anyone interested in **training**, **developing**, **fine-tuning**, or **deploying** LLMs

### ✅ Recommended Background

- Basic knowledge of **Python 🐍** and **PyTorch 🔥**
- Familiarity with **machine learning** and **neural networks**

---

## ⏳ Course Duration & Structure

This course takes approximately **4 hours** and is divided into **2 modules**:

### 📅 Week 1 – Module 1: Generative AI Architecture

- Introduction to **Generative AI** and its real-world applications
- Comparison of models: **Transformers**, **GANs**, **VAEs**, **RNNs**, **Diffusion models**
- Overview of training and fine-tuning methods
- Key tools and libraries for NLP
- 🧪 *Hands-on Lab:* Build a simple **chatbot** using **Hugging Face Transformers**

---

### 📅 Week 2 – Module 2: Data Preparation for LLMs

- Understanding **tokenization** methods: word-based, character-based, subword-based
- Implement tokenizers using libraries such as:
  - 📝 `nltk`
  - 🧠 `spaCy`
  - 🔠 `BertTokenizer`
  - ⚡ `XLNetTokenizer`
- Learn to use **data loaders** and **collate functions** for batch processing
- 🧾 Includes:
  - Cheat sheet with code snippets
  - Glossary for technical terms
  - Graded quiz at the end

> ⚠️ **Note:** This course does **not** cover data acquisition (e.g., web scraping), initial data cleaning, or the use of regular expressions. For lab exercises, ensure your data is pre-cleaned (remove symbols, unwanted characters, etc.).

---

## 📚 Learning Resources

This course includes:

- 🎥 **Video lectures** – Short, focused, and informative
- 📖 **Readings** – In-depth explanations
- 🧪 **Labs** – Hands-on coding exercises
- 📋 **Cheat Sheet** – Quick reference with code syntax
- 📓 **Glossary** – Definitions of technical terms
- ❓ **Practice Quizzes** – Self-checks at the end of each lesson
- 📝 **Graded Quizzes** – Assess your overall understanding

---

## 🌟 Get Started

You're now ready to explore **generative AI**, **LLMs**, and build skills that are highly valued in the AI job market. Good luck, and we hope you enjoy the journey! 🚀
